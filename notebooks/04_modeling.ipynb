{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Modelado y Prediccion del Tipo de Cambio USD/CLP\n",
    "\n",
    "Este notebook implementa y compara tres modelos de Machine Learning para predecir el tipo de cambio USD/CLP:\n",
    "\n",
    "1. **Random Forest**: Baseline ML robusto basado en arboles de decision\n",
    "2. **XGBoost**: Modelo principal de gradient boosting optimizado\n",
    "3. **AutoARIMA**: Baseline estadistico de series temporales\n",
    "\n",
    "## Estructura del Notebook\n",
    "\n",
    "1. Configuracion y carga de datos\n",
    "2. Preparacion de datos con validacion temporal\n",
    "3. Entrenamiento y evaluacion de modelos\n",
    "4. Comparacion de resultados\n",
    "5. Analisis de feature importance\n",
    "6. Persistencia del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importacion de Librerias y Configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones estandar\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizacion\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Persistencia\n",
    "import pickle\n",
    "\n",
    "# Configuracion\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Agregar el directorio raiz al path para importar modulos locales\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Importar utilidades personalizadas\n",
    "from src.utils.metrics import calculate_metrics, format_metrics, save_metrics\n",
    "\n",
    "print(\"Librerias importadas exitosamente\")\n",
    "print(f\"Directorio del proyecto: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Preparacion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de archivos\n",
    "DATA_PATH = project_root / \"data\" / \"processed\" / \"dolar_features.csv\"\n",
    "MODELS_DIR = project_root / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "print(\"Cargando datos procesados...\")\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['Fecha'])\n",
    "\n",
    "print(f\"\\nDatos cargados: {df.shape[0]} registros, {df.shape[1]} columnas\")\n",
    "print(f\"Rango de fechas: {df['Fecha'].min()} a {df['Fecha'].max()}\")\n",
    "print(f\"\\nColumnas disponibles:\\n{df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminar filas con valores nulos (debido a lags y moving averages)\n",
    "df_clean = df.dropna().copy()\n",
    "print(f\"\\nDatos despues de eliminar nulos: {df_clean.shape[0]} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features y target\n",
    "# Excluir: Fecha (indice temporal), Valor (target), statusCode (metadata)\n",
    "feature_cols = [col for col in df_clean.columns \n",
    "                if col not in ['Fecha', 'Valor', 'statusCode']]\n",
    "\n",
    "X = df_clean[feature_cols].values\n",
    "y = df_clean['Valor'].values\n",
    "dates = df_clean['Fecha'].values\n",
    "\n",
    "print(f\"Features seleccionadas ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Temporal de Datos\n",
    "\n",
    "Para series temporales, es crucial mantener el orden cronologico.\n",
    "Usamos un split 80/20 respetando la secuencia temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporal 80/20\n",
    "split_index = int(len(X) * 0.8)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "dates_train, dates_test = dates[:split_index], dates[split_index:]\n",
    "\n",
    "print(\"Division temporal de datos:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train set: {X_train.shape[0]} registros ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Rango: {dates_train[0]} a {dates_train[-1]}\")\n",
    "print(f\"\\nTest set:  {X_test.shape[0]} registros ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Rango: {dates_test[0]} a {dates_test[-1]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar TimeSeriesSplit para cross-validation\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "print(f\"\\nTimeSeriesSplit configurado con {n_splits} folds\")\n",
    "print(\"\\nEstructura de los folds:\")\n",
    "for i, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "    print(f\"  Fold {i}: Train={len(train_idx):4d} | Validation={len(val_idx):4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 1: Random Forest Regressor\n",
    "\n",
    "Baseline robusto basado en ensamble de arboles de decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODELO 1: RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hiperparametros\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"\\nHiperparametros:\")\n",
    "for param, value in rf_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Entrenar modelo\n",
    "print(\"\\nEntrenando Random Forest...\")\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo entrenado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "print(\"\\nEvaluando con Cross-Validation...\")\n",
    "cv_scores_rf = -cross_val_score(\n",
    "    rf_model, X_train, y_train,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nMAE por fold:\")\n",
    "for i, score in enumerate(cv_scores_rf, 1):\n",
    "    print(f\"  Fold {i}: {score:.2f}\")\n",
    "print(f\"\\nMAE promedio (CV): {cv_scores_rf.mean():.2f} (+/- {cv_scores_rf.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en test set\n",
    "print(\"\\nGenerando predicciones en test set...\")\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular metricas\n",
    "metrics_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "\n",
    "print(\"\\n\" + format_metrics(metrics_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo 2: XGBoost\n",
    "\n",
    "Modelo principal basado en gradient boosting optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODELO 2: XGBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hiperparametros\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "print(\"\\nHiperparametros:\")\n",
    "for param, value in xgb_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Entrenar modelo\n",
    "print(\"\\nEntrenando XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo entrenado exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "print(\"\\nEvaluando con Cross-Validation...\")\n",
    "cv_scores_xgb = -cross_val_score(\n",
    "    xgb_model, X_train, y_train,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nMAE por fold:\")\n",
    "for i, score in enumerate(cv_scores_xgb, 1):\n",
    "    print(f\"  Fold {i}: {score:.2f}\")\n",
    "print(f\"\\nMAE promedio (CV): {cv_scores_xgb.mean():.2f} (+/- {cv_scores_xgb.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en test set\n",
    "print(\"\\nGenerando predicciones en test set...\")\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calcular metricas\n",
    "metrics_xgb = calculate_metrics(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"\\n\" + format_metrics(metrics_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelo 3: AutoARIMA\n",
    "\n",
    "Baseline estadistico de series temporales univariadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODELO 3: AUTO ARIMA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hiperparametros\n",
    "arima_params = {\n",
    "    'seasonal': False,\n",
    "    'suppress_warnings': True,\n",
    "    'stepwise': True,\n",
    "    'trace': False,\n",
    "    'error_action': 'ignore',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "print(\"\\nHiperparametros:\")\n",
    "for param, value in arima_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Entrenar modelo (solo usa la serie temporal univariada)\n",
    "print(\"\\nEntrenando AutoARIMA...\")\n",
    "print(\"Nota: ARIMA solo utiliza la serie temporal univariada (no features)\")\n",
    "arima_model = auto_arima(y_train, **arima_params)\n",
    "\n",
    "print(f\"\\nModelo entrenado: {arima_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en test set\n",
    "print(\"\\nGenerando predicciones en test set...\")\n",
    "y_pred_arima = arima_model.predict(n_periods=len(y_test))\n",
    "\n",
    "# Calcular metricas\n",
    "metrics_arima = calculate_metrics(y_test, y_pred_arima)\n",
    "\n",
    "print(\"\\n\" + format_metrics(metrics_arima))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparacion de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest', 'XGBoost', 'AutoARIMA'],\n",
    "    'MAE': [metrics_rf['mae'], metrics_xgb['mae'], metrics_arima['mae']],\n",
    "    'RMSE': [metrics_rf['rmse'], metrics_xgb['rmse'], metrics_arima['rmse']],\n",
    "    'MAPE (%)': [metrics_rf['mape'], metrics_xgb['mape'], metrics_arima['mape']],\n",
    "    'R2': [metrics_rf['r2'], metrics_xgb['r2'], metrics_arima['r2']]\n",
    "})\n",
    "\n",
    "# Resaltar mejor valor en cada metrica\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACION DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identificar mejor modelo por metrica\n",
    "print(\"\\nMejor modelo por metrica:\")\n",
    "print(f\"  MAE:  {comparison_df.loc[comparison_df['MAE'].idxmin(), 'Modelo']} ({comparison_df['MAE'].min():.2f})\")\n",
    "print(f\"  RMSE: {comparison_df.loc[comparison_df['RMSE'].idxmin(), 'Modelo']} ({comparison_df['RMSE'].min():.2f})\")\n",
    "print(f\"  MAPE: {comparison_df.loc[comparison_df['MAPE (%)'].idxmin(), 'Modelo']} ({comparison_df['MAPE (%)'].min():.2f}%)\")\n",
    "print(f\"  R2:   {comparison_df.loc[comparison_df['R2'].idxmax(), 'Modelo']} ({comparison_df['R2'].max():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion comparativa de metricas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparacion de Metricas entre Modelos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# MAE\n",
    "axes[0, 0].bar(comparison_df['Modelo'], comparison_df['MAE'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 0].set_title('Mean Absolute Error (MAE)')\n",
    "axes[0, 0].set_ylabel('MAE')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].bar(comparison_df['Modelo'], comparison_df['RMSE'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0, 1].set_title('Root Mean Squared Error (RMSE)')\n",
    "axes[0, 1].set_ylabel('RMSE')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# MAPE\n",
    "axes[1, 0].bar(comparison_df['Modelo'], comparison_df['MAPE (%)'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1, 0].set_title('Mean Absolute Percentage Error (MAPE)')\n",
    "axes[1, 0].set_ylabel('MAPE (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].axhline(y=2, color='red', linestyle='--', label='Excelente (2%)')\n",
    "axes[1, 0].axhline(y=5, color='orange', linestyle='--', label='Bueno (5%)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# R2 Score\n",
    "axes[1, 1].bar(comparison_df['Modelo'], comparison_df['R2'], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1, 1].set_title('R² Score')\n",
    "axes[1, 1].set_ylabel('R²')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].axhline(y=0.95, color='green', linestyle='--', label='Objetivo (0.95)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizacion de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de predicciones vs valores reales\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "fig.suptitle('Predicciones vs Valores Reales en Test Set', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Random Forest\n",
    "axes[0].plot(dates_test, y_test, label='Valor Real', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(dates_test, y_pred_rf, label='Prediccion RF', linewidth=2, alpha=0.7)\n",
    "axes[0].set_title(f'Random Forest (MAE: {metrics_rf[\"mae\"]:.2f}, MAPE: {metrics_rf[\"mape\"]:.2f}%)')\n",
    "axes[0].set_ylabel('Valor USD/CLP')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].plot(dates_test, y_test, label='Valor Real', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(dates_test, y_pred_xgb, label='Prediccion XGB', linewidth=2, alpha=0.7)\n",
    "axes[1].set_title(f'XGBoost (MAE: {metrics_xgb[\"mae\"]:.2f}, MAPE: {metrics_xgb[\"mape\"]:.2f}%)')\n",
    "axes[1].set_ylabel('Valor USD/CLP')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# AutoARIMA\n",
    "axes[2].plot(dates_test, y_test, label='Valor Real', linewidth=2, alpha=0.7)\n",
    "axes[2].plot(dates_test, y_pred_arima, label='Prediccion ARIMA', linewidth=2, alpha=0.7)\n",
    "axes[2].set_title(f'AutoARIMA (MAE: {metrics_arima[\"mae\"]:.2f}, MAPE: {metrics_arima[\"mape\"]:.2f}%)')\n",
    "axes[2].set_xlabel('Fecha')\n",
    "axes[2].set_ylabel('Valor USD/CLP')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico comparativo de errores\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Distribucion de Errores por Modelo', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Calcular errores\n",
    "errors_rf = y_test - y_pred_rf\n",
    "errors_xgb = y_test - y_pred_xgb\n",
    "errors_arima = y_test - y_pred_arima\n",
    "\n",
    "# Random Forest\n",
    "axes[0].hist(errors_rf, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_title('Random Forest')\n",
    "axes[0].set_xlabel('Error (Real - Prediccion)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[1].hist(errors_xgb, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('XGBoost')\n",
    "axes[1].set_xlabel('Error (Real - Prediccion)')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# AutoARIMA\n",
    "axes[2].hist(errors_arima, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[2].set_title('AutoARIMA')\n",
    "axes[2].set_xlabel('Error (Real - Prediccion)')\n",
    "axes[2].set_ylabel('Frecuencia')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analisis de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance para Random Forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance - Random Forest:\")\n",
    "print(\"=\" * 60)\n",
    "print(rf_importance.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance para XGBoost\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance - XGBoost:\")\n",
    "print(\"=\" * 60)\n",
    "print(xgb_importance.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion de Feature Importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "fig.suptitle('Feature Importance por Modelo', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Top 15 features Random Forest\n",
    "top_rf = rf_importance.head(15)\n",
    "axes[0].barh(range(len(top_rf)), top_rf['Importance'])\n",
    "axes[0].set_yticks(range(len(top_rf)))\n",
    "axes[0].set_yticklabels(top_rf['Feature'])\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Random Forest - Top 15 Features')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top 15 features XGBoost\n",
    "top_xgb = xgb_importance.head(15)\n",
    "axes[1].barh(range(len(top_xgb)), top_xgb['Importance'])\n",
    "axes[1].set_yticks(range(len(top_xgb)))\n",
    "axes[1].set_yticklabels(top_xgb['Feature'])\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('XGBoost - Top 15 Features')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analisis de Residuos del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo basado en MAPE\n",
    "best_model_idx = comparison_df['MAPE (%)'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "\n",
    "# Obtener predicciones del mejor modelo\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = rf_model\n",
    "    y_pred_best = y_pred_rf\n",
    "    metrics_best = metrics_rf\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_model\n",
    "    y_pred_best = y_pred_xgb\n",
    "    metrics_best = metrics_xgb\n",
    "else:\n",
    "    best_model = arima_model\n",
    "    y_pred_best = y_pred_arima\n",
    "    metrics_best = metrics_arima\n",
    "\n",
    "print(f\"\\nModelo seleccionado: {best_model_name}\")\n",
    "print(f\"MAPE: {metrics_best['mape']:.2f}%\")\n",
    "print(f\"R²: {metrics_best['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de residuos\n",
    "residuals = y_test - y_pred_best\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f'Analisis de Residuos - {best_model_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Residuos vs Predicciones\n",
    "axes[0, 0].scatter(y_pred_best, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Valores Predichos')\n",
    "axes[0, 0].set_ylabel('Residuos')\n",
    "axes[0, 0].set_title('Residuos vs Predicciones')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribucion de residuos\n",
    "axes[0, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Residuos')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].set_title('Distribucion de Residuos')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Q-Q Plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuos en el tiempo\n",
    "axes[1, 1].plot(dates_test, residuals, alpha=0.7)\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Fecha')\n",
    "axes[1, 1].set_ylabel('Residuos')\n",
    "axes[1, 1].set_title('Residuos en el Tiempo')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadisticas de residuos\n",
    "print(\"\\nEstadisticas de Residuos:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Media:              {residuals.mean():.4f}\")\n",
    "print(f\"Mediana:            {np.median(residuals):.4f}\")\n",
    "print(f\"Desviacion Estandar:{residuals.std():.4f}\")\n",
    "print(f\"Minimo:             {residuals.min():.4f}\")\n",
    "print(f\"Maximo:             {residuals.max():.4f}\")\n",
    "print(f\"Percentil 25:       {np.percentile(residuals, 25):.4f}\")\n",
    "print(f\"Percentil 75:       {np.percentile(residuals, 75):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Persistencia del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el mejor modelo\n",
    "model_filename = f\"best_model_{best_model_name.lower().replace(' ', '_')}.pkl\"\n",
    "model_path = MODELS_DIR / model_filename\n",
    "\n",
    "print(f\"\\nGuardando modelo: {best_model_name}\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\"Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar nombres de features (solo para modelos ML, no ARIMA)\n",
    "if best_model_name != 'AutoARIMA':\n",
    "    feature_names_path = MODELS_DIR / \"feature_names.txt\"\n",
    "    with open(feature_names_path, 'w') as f:\n",
    "        for feature in feature_cols:\n",
    "            f.write(f\"{feature}\\n\")\n",
    "    print(f\"Nombres de features guardados en: {feature_names_path}\")\n",
    "else:\n",
    "    print(\"\\nNota: ARIMA no utiliza features, solo la serie temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar metricas\n",
    "metrics_output = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"training_date\": pd.Timestamp.now().isoformat(),\n",
    "    \"train_size\": int(len(X_train)),\n",
    "    \"test_size\": int(len(X_test)),\n",
    "    \"n_features\": len(feature_cols) if best_model_name != 'AutoARIMA' else 0,\n",
    "    \"metrics\": {\n",
    "        \"mae\": float(metrics_best['mae']),\n",
    "        \"rmse\": float(metrics_best['rmse']),\n",
    "        \"mape\": float(metrics_best['mape']),\n",
    "        \"r2\": float(metrics_best['r2']),\n",
    "        \"median_ae\": float(metrics_best['median_ae'])\n",
    "    },\n",
    "    \"comparison\": {\n",
    "        \"random_forest\": {\n",
    "            \"mae\": float(metrics_rf['mae']),\n",
    "            \"mape\": float(metrics_rf['mape']),\n",
    "            \"r2\": float(metrics_rf['r2'])\n",
    "        },\n",
    "        \"xgboost\": {\n",
    "            \"mae\": float(metrics_xgb['mae']),\n",
    "            \"mape\": float(metrics_xgb['mape']),\n",
    "            \"r2\": float(metrics_xgb['r2'])\n",
    "        },\n",
    "        \"autoarima\": {\n",
    "            \"mae\": float(metrics_arima['mae']),\n",
    "            \"mape\": float(metrics_arima['mape']),\n",
    "            \"r2\": float(metrics_arima['r2'])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "metrics_path = MODELS_DIR / \"metrics.json\"\n",
    "save_metrics(metrics_output, str(metrics_path))\n",
    "print(f\"Metricas guardadas en: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONCLUSIONES Y RECOMENDACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1. MODELO SELECCIONADO: {best_model_name}\")\n",
    "print(f\"   - MAPE: {metrics_best['mape']:.2f}%\")\n",
    "print(f\"   - R²: {metrics_best['r2']:.4f}\")\n",
    "print(f\"   - MAE: {metrics_best['mae']:.2f} CLP\")\n",
    "\n",
    "# Evaluacion de performance\n",
    "if metrics_best['mape'] < 2:\n",
    "    performance = \"EXCELENTE\"\n",
    "elif metrics_best['mape'] < 5:\n",
    "    performance = \"BUENO\"\n",
    "else:\n",
    "    performance = \"ACEPTABLE\"\n",
    "\n",
    "print(f\"\\n2. EVALUACION DE PERFORMANCE: {performance}\")\n",
    "\n",
    "print(\"\\n3. FEATURES MAS IMPORTANTES:\")\n",
    "if best_model_name == 'Random Forest':\n",
    "    top_features = rf_importance.head(5)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    top_features = xgb_importance.head(5)\n",
    "else:\n",
    "    print(\"   N/A (ARIMA no utiliza features)\")\n",
    "    top_features = None\n",
    "\n",
    "if top_features is not None:\n",
    "    for idx, row in top_features.iterrows():\n",
    "        print(f\"   - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n4. RECOMENDACIONES PARA PRODUCCION:\")\n",
    "if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "    print(\"   - Implementar pipeline de prediccion con preprocesamiento\")\n",
    "    print(\"   - Monitorear drift en features clave\")\n",
    "    print(\"   - Reentrenar modelo mensualmente o cuando MAPE > 3%\")\n",
    "    print(\"   - Implementar validacion de inputs antes de prediccion\")\n",
    "    print(\"   - Configurar alertas para predicciones anomalas\")\n",
    "else:\n",
    "    print(\"   - ARIMA requiere solo la serie temporal\")\n",
    "    print(\"   - Actualizar modelo con datos recientes regularmente\")\n",
    "    print(\"   - Considerar SARIMAX si aparece estacionalidad\")\n",
    "\n",
    "print(\"\\n5. PROXIMOS PASOS:\")\n",
    "print(\"   - Implementar API de prediccion (FastAPI)\")\n",
    "print(\"   - Crear pipeline de reentrenamiento automatizado\")\n",
    "print(\"   - Desarrollar dashboard de monitoreo\")\n",
    "print(\"   - Implementar tests de validacion de modelo\")\n",
    "print(\"   - Explorar ensemble de modelos para mayor robustez\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de prediccion con el mejor modelo\n",
    "print(\"\\nEJEMPLO DE PREDICCION:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tomar ultima observacion del test set\n",
    "sample_idx = -1\n",
    "sample_date = dates_test[sample_idx]\n",
    "sample_real = y_test[sample_idx]\n",
    "\n",
    "if best_model_name != 'AutoARIMA':\n",
    "    sample_features = X_test[sample_idx].reshape(1, -1)\n",
    "    sample_pred = best_model.predict(sample_features)[0]\n",
    "else:\n",
    "    # Para ARIMA, usar la ultima prediccion\n",
    "    sample_pred = y_pred_best[sample_idx]\n",
    "\n",
    "error_abs = abs(sample_real - sample_pred)\n",
    "error_pct = (error_abs / sample_real) * 100\n",
    "\n",
    "print(f\"Fecha:             {sample_date}\")\n",
    "print(f\"Valor Real:        {sample_real:.2f} CLP\")\n",
    "print(f\"Valor Predicho:    {sample_pred:.2f} CLP\")\n",
    "print(f\"Error Absoluto:    {error_abs:.2f} CLP\")\n",
    "print(f\"Error Porcentual:  {error_pct:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
